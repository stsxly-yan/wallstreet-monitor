éå¸¸æ£’çš„åé¦ˆï¼åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œä¿æŒåŠŸèƒ½çš„å»¶ç»­æ€§ç¡®å®éå¸¸é‡è¦ã€‚

æˆ‘å·²ç»æŠŠ â€œè‡ªåŠ¨åˆ·æ–°é¢‘ç‡æ»‘æ†â€ åŠ å›æ¥äº†ï¼Œå¹¶ä¸”åœ¨ä¾§è¾¹æ æœ€æ˜¾çœ¼çš„ä½ç½®å¢åŠ äº†ä¸€ä¸ª â€œğŸ”„ ç«‹å³åˆ·æ–°æ•°æ®â€ çš„æŒ‰é’®ã€‚

ğŸ› ï¸ æ›´æ–° opp.py (v3.3 å®Œç¾äº¤äº’ç‰ˆ)
æœ¬æ¬¡æ›´æ–°å†…å®¹ï¼š

ä¾§è¾¹æ å›å½’ï¼šæ‰¾å›äº†â€œè‡ªåŠ¨åˆ·æ–°é¢‘ç‡â€æ»‘æ†ã€‚

æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®ï¼šç‚¹å‡»ä¾§è¾¹æ çš„ç»¿è‰²æŒ‰é’®ï¼Œå³å¯å¼ºåˆ¶é‡æ–°æ‹‰å–æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬ CNNã€è‚¡ä»·ã€æ–°é—»ï¼‰ã€‚

åŠŸèƒ½ä¿ç•™ï¼šå®Œç¾ä¿ç•™äº†ä¸Šä¸€ç‰ˆçš„ CNN ä»ªè¡¨ç›˜ã€æ–°é—»æ—¶é—´æ’åº å’Œ 5çº§æƒ…ç»ªé¢œè‰²ã€‚

(æ³¨ï¼šrequirements.txt ä¸éœ€è¦æ”¹åŠ¨ï¼Œç›´æ¥æ›´æ–°ä¸‹é¢è¿™ä¸ªä»£ç æ–‡ä»¶å³å¯)

Python

import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
from openai import OpenAI
from textblob import TextBlob
import plotly.graph_objects as go
import requests
import datetime
import time

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="DeepSeek æ™ºèƒ½é£æ§ä»ªè¡¨ç›˜", layout="wide", page_icon="ğŸ¦ˆ")

# --- 2. ä¾§è¾¹æ ï¼šå…¨å±€æ§åˆ¶ä¸­å¿ƒ ---
st.sidebar.title("âš™ï¸ æ§åˆ¶ä¸­å¿ƒ")

# A. åˆ·æ–°æ§åˆ¶ (æ–°åŠ å›æ¥çš„åŠŸèƒ½)
st.sidebar.subheader("â±ï¸ åˆ·æ–°è®¾ç½®")
# æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
if st.sidebar.button("ğŸ”„ ç«‹å³åˆ·æ–°æ•°æ® (Refresh Now)", type="primary"):
    st.rerun()

# è‡ªåŠ¨åˆ·æ–°æ»‘æ†
refresh_rate = st.sidebar.slider("è‡ªåŠ¨åˆ·æ–°é—´éš” (åˆ†é’Ÿ)", 5, 60, 30, help="é¡µé¢ä¼šè‡ªåŠ¨å€’è®¡æ—¶åˆ·æ–°ï¼Œæˆ–ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®æ‰‹åŠ¨åˆ·æ–°")

# B. API è®¾ç½®
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ¤– æ¨¡å‹è®¾ç½®")
api_key = st.sidebar.text_input("DeepSeek API Key", type="password", placeholder="sk-...")
MODEL_NAME = "deepseek-chat"
BASE_URL = "https://api.deepseek.com"

# C. å¿«æ·å·¥å…·
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”— å¿«æ·å…¥å£")
st.sidebar.markdown("[ğŸ“… è´¢ç»æ—¥å† (Investing)](https://cn.investing.com/economic-calendar/)")
st.sidebar.caption(f"ä¸Šæ¬¡æ›´æ–°: {datetime.datetime.now().strftime('%H:%M:%S')}")

# --- 3. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

# A. è·å– CNN ææ…Œè´ªå©ªæŒ‡æ•°
@st.cache_data(ttl=3600) 
def get_cnn_fear_greed_index():
    try:
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, headers=headers, timeout=5)
        if r.status_code == 200:
            data = r.json()
            latest = data['fear_and_greed_historical']['data'][-1]
            return int(latest['y'])
        return None
    except:
        return None

# B. ç”»ä»ªè¡¨ç›˜
def plot_gauge(score):
    if score is None: return go.Figure()
    
    # åŠ¨æ€å˜è‰²é€»è¾‘
    color = "#GRAY"
    if score > 75: color = "#FF4B4B" # æåº¦è´ªå©ª(çº¢)
    elif score > 55: color = "#FF8C00" # è´ªå©ª(æ©™)
    elif score < 25: color = "#006400" # æåº¦ææ…Œ(æ·±ç»¿)
    elif score < 45: color = "#00CC96" # ææ…Œ(ç»¿)
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': "CNN ææ…Œè´ªå©ªæŒ‡æ•°", 'font': {'size': 20}},
        number = {'font': {'size': 40, 'color': color}},
        gauge = {
            'axis': {'range': [0, 100]},
            'bar': {'color': color},
            'steps': [
                {'range': [0, 25], 'color': 'rgba(0, 255, 0, 0.2)'},
                {'range': [75, 100], 'color': 'rgba(255, 0, 0, 0.2)'}
            ],
        }
    ))
    fig.update_layout(height=250, margin=dict(l=10, r=10, t=40, b=10))
    return fig

# C. æƒ…ç»ªåˆ†æ
def analyze_sentiment_tag(text):
    analysis = TextBlob(text)
    score = analysis.sentiment.polarity
    if score > 0.3: return "ğŸŸ¢ æåº¦ä¹è§‚", "green", score
    elif 0.1 < score <= 0.3: return "ğŸ¥¬ åå¤š", "green", score
    elif -0.1 <= score <= 0.1: return "âšª ä¸­æ€§", "gray", score
    elif -0.3 <= score < -0.1: return "ğŸŸ  åç©º", "orange", score
    else: return "ğŸ”´ æåº¦æ‚²è§‚", "red", score

# D. è·å–å¸‚åœºæ•°æ®
@st.cache_data(ttl=300)
def get_market_data():
    tickers = yf.Tickers("SPY QQQ IEF") 
    hist = tickers.history(period="3mo")
    return hist

# --- 4. ä¸»ç•Œé¢å¸ƒå±€ ---
st.title("ğŸ¦ˆ åå°”è¡—é£å‘æ ‡ (Pro Dashboard)")
st.caption(f"æœ€è¿‘æ•°æ®æ‹‰å–æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

try:
    # 1. æ•°æ®å±‚
    market_data = get_market_data()
    cnn_score = get_cnn_fear_greed_index()
    
    def safe_metric(sym):
        try:
            s = market_data['Close'][sym].dropna()
            if len(s) < 2: return 0, 0
            val = s.iloc[-1]
            chg = val - s.iloc[-2]
            return val, chg
        except: return 0, 0

    spy_val, spy_chg = safe_metric("SPY")
    qqq_val, qqq_chg = safe_metric("QQQ")
    ief_val, ief_chg = safe_metric("IEF")

    # 2. å¯è§†åŒ–å±‚
    col_metrics, col_gauge = st.columns([2, 1])

    with col_metrics:
        st.subheader("1. æ ¸å¿ƒèµ„äº§ç›‘æ§")
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ“ˆ æ ‡æ™®500 (SPY)", f"${spy_val:.1f}", f"{spy_chg:.2f}")
        c2.metric("ğŸ’» çº³æŒ‡ (QQQ)", f"${qqq_val:.1f}", f"{qqq_chg:.2f}")
        c3.metric("âš–ï¸ å›½å€º (IEF)", f"${ief_val:.2f}", f"{ief_chg:.2f}", help="çº¢è·Œ=åˆ©ç‡æ¶¨(åˆ©ç©º)")
        
        st.markdown("---")
        st.subheader("2. ä»·æ ¼è¶‹åŠ¿")
        chart_df = pd.DataFrame({'SPY': market_data['Close']['SPY'], 'QQQ': market_data['Close']['QQQ']})
        st.line_chart(chart_df, height=200)

    with col_gauge:
        st.subheader("ææ…Œæƒ…ç»ª")
        if cnn_score is not None:
            fig = plot_gauge(cnn_score)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("CNN æ•°æ®æºè¿æ¥è¶…æ—¶")

except Exception as e:
    st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")

# --- 5. æ–°é—»æƒ…æŠ¥æµ (å«æ—¶é—´æ’åº) ---
st.markdown("---")
st.subheader("3. å…¨çƒæƒ…æŠ¥æµ (Live News Feed)")

rss_feeds = {
    "Goldman Sachs": "https://news.google.com/rss/search?q=Goldman+Sachs+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Morgan Stanley": "https://news.google.com/rss/search?q=Morgan+Stanley+market+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Market Risk": "https://news.google.com/rss/search?q=stock+market+crash+warning+when:2d&hl=en-US&gl=US&ceid=US:en"
}

# æŠ“å–é€»è¾‘
all_news = []
for src, url in rss_feeds.items():
    try:
        f = feedparser.parse(url)
        for e in f.entries:
            ts = 0
            time_str = "æœªçŸ¥æ—¶é—´"
            if hasattr(e, 'published_parsed') and e.published_parsed:
                ts = time.mktime(e.published_parsed)
                time_str = datetime.datetime.fromtimestamp(ts).strftime('%m-%d %H:%M')
            
            all_news.append({
                "source": src, "title": e.title, "link": e.link, 
                "time_str": time_str, "timestamp": ts
            })
    except: pass

# æ’åºï¼šæœ€æ–°çš„åœ¨ä¸Šé¢
all_news.sort(key=lambda x: x['timestamp'], reverse=True)

c_ai, c_list = st.columns([1, 1.5])

with c_ai:
    st.markdown("#### ğŸ§  DeepSeek ç ”æŠ¥")
    if st.button("âš¡ ç”Ÿæˆç®€æŠ¥", type="primary"):
        if not api_key: st.warning("è¯·å…ˆåœ¨å·¦ä¾§è®¾ç½® API Key")
        else:
            # æå–å‰10æ¡æœ€æ–°æ–°é—»
            context = "\n".join([f"- [{n['source']}] {n['title']}" for n in all_news[:10]])
            try:
                client = OpenAI(api_key=api_key, base_url=BASE_URL)
                prompt = f"ä½œä¸ºé£æ§å®˜ï¼Œè¯·æ ¹æ®ä»¥ä¸‹æœ€æ–°æ–°é—»åˆ†æç¾è‚¡é£é™©ï¼š\n{context}\nè¯·ç”¨Markdownåˆ—è¡¨è¾“å‡ºï¼š1.é£é™©è¯„çº§(0-10) 2.æœºæ„åˆ†æ­§ 3.æ“ä½œå»ºè®®"
                with st.spinner("AI æ­£åœ¨åˆ†æ..."):
                    resp = client.chat.completions.create(
                        model=MODEL_NAME, messages=[{"role":"user", "content":prompt}])
                    st.success("åˆ†æå®Œæˆ")
                    st.markdown(resp.choices[0].message.content)
            except Exception as e: st.error(str(e))

with c_list:
    st.markdown("#### ğŸ“° å®æ—¶èµ„è®¯æµ")
    container = st.container(height=600)
    with container:
        for n in all_news[:25]:
            label, color, score = analyze_sentiment_tag(n['title'])
            st.markdown(f":{color}[**{label}**] {n['title']}")
            st.caption(f"ğŸ•’ {n['time_str']} | {n['source']} | [åŸæ–‡]({n['link']})")
            st.divider()

# --- è‡ªåŠ¨åˆ·æ–°é€»è¾‘ (ä¸é˜»å¡UI) ---
if refresh_rate:
    time.sleep(1) # è¿™é‡Œçš„ç®€å•é€»è¾‘ï¼šé˜²æ­¢è„šæœ¬è·‘å¾—å¤ªå¿«ï¼Œå®é™…åˆ·æ–°ä¾èµ–Streamlitçš„rerunæœºåˆ¶æˆ–æ‰‹åŠ¨æŒ‰é’®
    # æ³¨æ„ï¼šå®Œå…¨çš„è‡ªåŠ¨åˆ·æ–°é€šå¸¸éœ€è¦ streamlit-autorefresh åº“
    # ä½†ä¸ºäº†ä¸å¢åŠ ä¾èµ–ï¼Œæˆ‘ä»¬è¿™é‡Œä¾é ç”¨æˆ·çš„â€œæ‰‹åŠ¨åˆ·æ–°â€æŒ‰é’®ä¸ºä¸»ï¼Œ
    # æˆ–è€…æ¯æ¬¡æœ‰äº¤äº’æ—¶é¡µé¢éƒ½ä¼šè‡ªåŠ¨åˆ·æ–°æ•°æ®(å› ä¸ºcache expired)
