import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
from openai import OpenAI
from textblob import TextBlob
import plotly.graph_objects as go
import requests
import datetime
import time

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="DeepSeek æ™ºèƒ½é£æ§ä»ªè¡¨ç›˜", layout="wide", page_icon="ğŸ¦ˆ")

# --- 2. ä¾§è¾¹æ  ---
st.sidebar.title("âš™ï¸ è®¾ç½®")
api_key = st.sidebar.text_input("DeepSeek API Key", type="password", placeholder="sk-...")
MODEL_NAME = "deepseek-chat"
BASE_URL = "https://api.deepseek.com"
st.sidebar.info("å·²å¯ç”¨ CNN ææ…ŒæŒ‡æ•°å®æ—¶å›¾è¡¨")

# --- 3. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

# A. è·å– CNN ææ…Œè´ªå©ªæŒ‡æ•° (é»‘ç§‘æŠ€ç‰ˆ)
@st.cache_data(ttl=3600) # ç¼“å­˜1å°æ—¶ï¼Œé¿å…é¢‘ç¹è¯·æ±‚è¢«å°
def get_cnn_fear_greed_index():
    try:
        # è¿™æ˜¯ä¸€ä¸ªéå®˜æ–¹ä½†ç›®å‰ç¨³å®šçš„ CNN æ•°æ®æ¥å£
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        r = requests.get(url, headers=headers, timeout=5)
        if r.status_code == 200:
            data = r.json()
            # è·å–æœ€æ–°çš„ä¸€æ¡æ•°æ®
            latest_data = data['fear_and_greed_historical']['data'][-1]
            score = int(latest_data['y'])
            timestamp = latest_data['x'] # æ—¶é—´æˆ³
            return score
        else:
            return None
    except:
        return None

# B. ç”»ä»ªè¡¨ç›˜ (Gauge Chart)
def plot_gauge(score):
    if score is None:
        return go.Figure() # è¿”å›ç©ºå›¾
    
    # é¢œè‰²é€»è¾‘
    color = "red"
    if score > 75: color = "#FF4B4B" # æåº¦è´ªå©ª (çº¢)
    elif score > 55: color = "#FF8C00" # è´ªå©ª (æ©™)
    elif score > 45: color = "#GRAY" # ä¸­æ€§
    elif score > 25: color = "#00CC96" # ææ…Œ (ç»¿-æœºä¼š)
    else: color = "#006400" # æåº¦ææ…Œ (æ·±ç»¿-å¤§æœºä¼š)

    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': "CNN ææ…Œè´ªå©ªæŒ‡æ•°", 'font': {'size': 20}},
        number = {'font': {'size': 40, 'color': color}},
        gauge = {
            'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': "white"},
            'bar': {'color': color},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 25], 'color': 'rgba(0, 255, 0, 0.3)'},  # æåº¦ææ…ŒåŒºåŸŸ
                {'range': [75, 100], 'color': 'rgba(255, 0, 0, 0.3)'} # æåº¦è´ªå©ªåŒºåŸŸ
            ],
        }
    ))
    # è°ƒæ•´å¸ƒå±€å¤§å°
    fig.update_layout(height=250, margin=dict(l=10, r=10, t=40, b=10))
    return fig

# C. æƒ…ç»ªåˆ†æ
def analyze_sentiment_tag(text):
    analysis = TextBlob(text)
    score = analysis.sentiment.polarity
    if score > 0.3: return "ğŸŸ¢ æåº¦ä¹è§‚", "green", score
    elif 0.1 < score <= 0.3: return "ğŸ¥¬ åå¤š", "green", score
    elif -0.1 <= score <= 0.1: return "âšª ä¸­æ€§", "gray", score
    elif -0.3 <= score < -0.1: return "ğŸŸ  åç©º", "orange", score
    else: return "ğŸ”´ æåº¦æ‚²è§‚", "red", score

@st.cache_data(ttl=300)
def get_market_data():
    tickers = yf.Tickers("SPY QQQ IEF") 
    hist = tickers.history(period="3mo")
    return hist

# --- 4. ä¸»ç•Œé¢ ---
st.title("ğŸ¦ˆ åå°”è¡—é£å‘æ ‡ (Live Update)")
st.caption(f"æ›´æ–°: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# 1. å¸‚åœºæ•°æ®
try:
    market_data = get_market_data()
    
    def safe_metric(sym):
        try:
            s = market_data['Close'][sym].dropna()
            if len(s) < 2: return 0, 0
            val = s.iloc[-1]
            chg = val - s.iloc[-2]
            return val, chg
        except: return 0, 0

    spy_val, spy_chg = safe_metric("SPY")
    qqq_val, qqq_chg = safe_metric("QQQ")
    ief_val, ief_chg = safe_metric("IEF")
    
    # è·å– CNN åˆ†æ•°
    cnn_score = get_cnn_fear_greed_index()

    # å¸ƒå±€ï¼šå·¦è¾¹æ˜¯æŒ‡æ•°æ®ï¼Œå³è¾¹æ˜¯ä»ªè¡¨ç›˜
    col_metrics, col_gauge = st.columns([2, 1])

    with col_metrics:
        st.subheader("1. æ ¸å¿ƒèµ„äº§")
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ“ˆ æ ‡æ™®500 (SPY)", f"${spy_val:.1f}", f"{spy_chg:.2f}")
        c2.metric("ğŸ’» çº³æŒ‡ (QQQ)", f"${qqq_val:.1f}", f"{qqq_chg:.2f}")
        c3.metric("âš–ï¸ å›½å€º (IEF)", f"${ief_val:.2f}", f"{ief_chg:.2f}", help="çº¢è·Œ=åˆ©ç‡æ¶¨é£é™©")
        
        st.markdown("---")
        st.subheader("2. è¶‹åŠ¿å›¾")
        chart_data = pd.DataFrame({
            'SPY': market_data['Close']['SPY'],
            'QQQ': market_data['Close']['QQQ']
        })
        st.line_chart(chart_data, height=200)

    with col_gauge:
        st.subheader("æƒ…ç»ªä»ªè¡¨ç›˜")
        # æ˜¾ç¤º CNN å›¾è¡¨
        if cnn_score is not None:
            fig = plot_gauge(cnn_score)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("CNN æ•°æ®æºæš‚æ—¶è¿æ¥è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•æˆ–å‚è€ƒ VIXã€‚")
            st.metric("æ›¿ä»£æŒ‡æ ‡ VIX", "20.4", "+1.2") # ç¤ºä¾‹

except Exception as e:
    st.error(f"æ•°æ®åŠ è½½é”™è¯¯: {e}")

# --- 3. æ–°é—»èšåˆ (æŒ‰æ—¶é—´æ’åº) ---
st.markdown("---")
st.subheader("3. å…¨çƒæƒ…æŠ¥æµ (Real-time News)")

rss_feeds = {
    "Goldman Sachs": "https://news.google.com/rss/search?q=Goldman+Sachs+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Morgan Stanley": "https://news.google.com/rss/search?q=Morgan+Stanley+market+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Market Risk": "https://news.google.com/rss/search?q=stock+market+crash+warning+when:2d&hl=en-US&gl=US&ceid=US:en"
}

# 1. æŠ“å–å¹¶åˆå¹¶æ‰€æœ‰æ–°é—»
all_news_items = []
for src, url in rss_feeds.items():
    try:
        f = feedparser.parse(url)
        for e in f.entries:
            # è§£ææ—¶é—´
            published_time = "æœªçŸ¥æ—¶é—´"
            timestamp = 0
            if hasattr(e, 'published_parsed') and e.published_parsed:
                # è½¬æ¢ä¸ºæ—¶é—´æˆ³ä»¥ä¾¿æ’åº
                timestamp = time.mktime(e.published_parsed)
                # è½¬æ¢ä¸ºæ˜“è¯»æ ¼å¼ (å¹´-æœˆ-æ—¥ æ—¶:åˆ†)
                dt_object = datetime.datetime.fromtimestamp(timestamp)
                published_time = dt_object.strftime('%Y-%m-%d %H:%M')
            
            all_news_items.append({
                "source": src,
                "title": e.title,
                "link": e.link,
                "time_str": published_time,
                "timestamp": timestamp
            })
    except: pass

# 2. æŒ‰æ—¶é—´æˆ³å€’åºæ’åº (æœ€æ–°çš„åœ¨æœ€å‰)
all_news_items.sort(key=lambda x: x['timestamp'], reverse=True)

# 3. æ˜¾ç¤ºæ–°é—»
col_ui_1, col_ui_2 = st.columns([1, 1.5])

with col_ui_1:
    st.markdown("#### ğŸ¤– AI ç®€æŠ¥")
    if st.button("âš¡ åˆ†ææœ€æ–°æ–°é—»", type="primary"):
        if not api_key: st.warning("éœ€è¾“å…¥ Key")
        else:
            # åªå‘ç»™ AI å‰ 10 æ¡æœ€æ–°çš„ï¼Œé¿å… Token å¤ªå¤š
            top_news = "\n".join([f"- {n['title']}" for n in all_news_items[:10]])
            try:
                client = OpenAI(api_key=api_key, base_url=BASE_URL)
                prompt = f"åˆ†æä»¥ä¸‹æœ€æ–°ç¾è‚¡æ–°é—»é£é™©:\n{top_news}\nç»™å‡ºä¸­æ–‡ç®€æŠ¥ã€‚"
                with st.spinner("AI åˆ†æä¸­..."):
                    resp = client.chat.completions.create(
                        model=MODEL_NAME, messages=[{"role":"user", "content":prompt}])
                    st.markdown(resp.choices[0].message.content)
            except Exception as e: st.error(str(e))

with col_ui_2:
    st.markdown("#### ğŸ“° æœ€æ–°èµ„è®¯ (æŒ‰æ—¶é—´æ’åº)")
    news_container = st.container(height=600)
    with news_container:
        for item in all_news_items[:20]: # åªæ˜¾ç¤ºæœ€æ–°çš„20æ¡
            label, color, score = analyze_sentiment_tag(item['title'])
            
            # å¸ƒå±€ï¼šæ ‡é¢˜è¡Œ
            st.markdown(f":{color}[**{label}**] [{item['source']}] **{item['title']}**")
            
            # è¯¦æƒ…è¡Œ (ç°è‰²å°å­—æ˜¾ç¤ºæ—¶é—´)
            st.caption(f"ğŸ•’ {item['time_str']} | [é˜…è¯»åŸæ–‡]({item['link']})")
            st.divider()
