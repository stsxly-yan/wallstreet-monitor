import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
from openai import OpenAI
from textblob import TextBlob
import plotly.graph_objects as go
import requests
import datetime
import time
import random

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="DeepSeek æ™ºèƒ½é£æ§ä»ªè¡¨ç›˜", layout="wide", page_icon="ğŸ¦ˆ")

# --- 2. ä¾§è¾¹æ ï¼šå…¨å±€æ§åˆ¶ä¸­å¿ƒ ---
st.sidebar.title("âš™ï¸ æ§åˆ¶ä¸­å¿ƒ")

# A. åˆ·æ–°æ§åˆ¶
st.sidebar.subheader("â±ï¸ åˆ·æ–°è®¾ç½®")
if st.sidebar.button("ğŸ”„ ç«‹å³åˆ·æ–°æ•°æ® (Refresh Now)", type="primary"):
    st.rerun()

refresh_rate = st.sidebar.slider("è‡ªåŠ¨åˆ·æ–°é—´éš” (åˆ†é’Ÿ)", 5, 60, 30)

# B. API è®¾ç½®
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ¤– æ¨¡å‹è®¾ç½®")
api_key = st.sidebar.text_input("DeepSeek API Key", type="password", placeholder="sk-...")
MODEL_NAME = "deepseek-chat"
BASE_URL = "https://api.deepseek.com"

# C. å¿«æ·å·¥å…·
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”— å¿«æ·å…¥å£")
st.sidebar.markdown("[ğŸ“… è´¢ç»æ—¥å† (Investing)](https://cn.investing.com/economic-calendar/)")
st.sidebar.caption(f"æ›´æ–°æ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}")

# --- 3. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

# A. è·å– CNN ææ…Œè´ªå©ªæŒ‡æ•° (å¢å¼ºä¼ªè£…ç‰ˆ)
@st.cache_data(ttl=3600) 
def get_cnn_fear_greed_index():
    try:
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        # ä¼ªè£…æˆçœŸå®çš„ Mac Chrome æµè§ˆå™¨
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://www.cnn.com/",
            "Accept-Language": "en-US,en;q=0.9",
            "Cache-Control": "no-cache",
            "Pragma": "no-cache"
        }
        # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 10ç§’
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            data = r.json()
            latest = data['fear_and_greed_historical']['data'][-1]
            return int(latest['y']), "CNN å®˜æ–¹æ•°æ®"
        return None, None
    except:
        return None, None

# B. ç”»ä»ªè¡¨ç›˜ (é€šç”¨ç‰ˆ)
def plot_gauge(score, source_label):
    if score is None: return go.Figure()
    
    # åŠ¨æ€å˜è‰²
    color = "#GRAY"
    if score > 75: color = "#FF4B4B" # æåº¦è´ªå©ª
    elif score > 55: color = "#FF8C00" # è´ªå©ª
    elif score < 25: color = "#006400" # æåº¦ææ…Œ
    elif score < 45: color = "#00CC96" # ææ…Œ
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': f"å¸‚åœºæƒ…ç»ª ({source_label})", 'font': {'size': 18}},
        number = {'font': {'size': 40, 'color': color}},
        gauge = {
            'axis': {'range': [0, 100]},
            'bar': {'color': color},
            'steps': [
                {'range': [0, 25], 'color': 'rgba(0, 255, 0, 0.2)'},
                {'range': [75, 100], 'color': 'rgba(255, 0, 0, 0.2)'}
            ],
        }
    ))
    fig.update_layout(height=250, margin=dict(l=10, r=10, t=40, b=10))
    return fig

# C. æƒ…ç»ªåˆ†æ
def analyze_sentiment_tag(text):
    analysis = TextBlob(text)
    score = analysis.sentiment.polarity
    if score > 0.3: return "ğŸŸ¢ æåº¦ä¹è§‚", "green", score
    elif 0.1 < score <= 0.3: return "ğŸ¥¬ åå¤š", "green", score
    elif -0.1 <= score <= 0.1: return "âšª ä¸­æ€§", "gray", score
    elif -0.3 <= score < -0.1: return "ğŸŸ  åç©º", "orange", score
    else: return "ğŸ”´ æåº¦æ‚²è§‚", "red", score

# D. è®¡ç®— RSI
def calculate_rsi(data, window=14):
    try:
        delta = data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    except:
        return pd.Series([50]*len(data))

# E. è·å–å¸‚åœºæ•°æ®
@st.cache_data(ttl=300)
def get_market_data():
    tickers = yf.Tickers("SPY QQQ IEF") 
    hist = tickers.history(period="3mo")
    return hist

# --- 4. ä¸»ç•Œé¢å¸ƒå±€ ---
st.title("ğŸ¦ˆ åå°”è¡—é£å‘æ ‡ (Pro)")
st.caption(f"æ•°æ®æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

try:
    # 1. æ•°æ®å±‚
    market_data = get_market_data()
    
    def safe_metric(sym):
        try:
            s = market_data['Close'][sym].dropna()
            if len(s) < 2: return 0, 0
            val = s.iloc[-1]
            chg = val - s.iloc[-2]
            return val, chg
        except: return 0, 0

    spy_val, spy_chg = safe_metric("SPY")
    qqq_val, qqq_chg = safe_metric("QQQ")
    ief_val, ief_chg = safe_metric("IEF")

    # 2. æ™ºèƒ½ä»ªè¡¨ç›˜é€»è¾‘
    # ä¼˜å…ˆå– CNNï¼Œå¦‚æœå¤±è´¥ï¼Œå– RSI æ¨¡æ‹Ÿ
    gauge_score, gauge_source = get_cnn_fear_greed_index()
    
    # è®¡ç®— RSI ä½œä¸ºå¤‡ç”¨
    try:
        spy_data = market_data.xs('SPY', level=1, axis=1) if isinstance(market_data.columns, pd.MultiIndex) else market_data
        rsi_val = calculate_rsi(spy_data).iloc[-1]
    except:
        rsi_val = 50

    # æ›¿è¡¥é€»è¾‘
    if gauge_score is None:
        gauge_score = rsi_val
        gauge_source = "RSI æ¨¡æ‹Ÿå€¼ (CNNè¶…æ—¶)"

    # 3. å¯è§†åŒ–å¸ƒå±€
    col_metrics, col_gauge = st.columns([2, 1])

    with col_metrics:
        st.subheader("1. æ ¸å¿ƒèµ„äº§")
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ“ˆ æ ‡æ™®500", f"${spy_val:.1f}", f"{spy_chg:.2f}")
        c2.metric("ğŸ’» çº³æŒ‡", f"${qqq_val:.1f}", f"{qqq_chg:.2f}")
        c3.metric("âš–ï¸ å›½å€º", f"${ief_val:.2f}", f"{ief_chg:.2f}", help="çº¢è·Œ=åˆ©ç©º")
        
        st.markdown("---")
        st.subheader("2. è¶‹åŠ¿å›¾")
        chart_df = pd.DataFrame({'SPY': market_data['Close']['SPY'], 'QQQ': market_data['Close']['QQQ']})
        st.line_chart(chart_df, height=200)

    with col_gauge:
        st.subheader("ææ…Œæƒ…ç»ªè¡¨")
        # æ— è®º CNN æ˜¯å¦æˆåŠŸï¼Œè¿™é‡Œéƒ½ä¼šæ˜¾ç¤ºä¸€ä¸ªå›¾
        fig = plot_gauge(gauge_score, gauge_source)
        st.plotly_chart(fig, use_container_width=True)
        if "RSI" in gauge_source:
            st.caption("âš ï¸ æ³¨ï¼šå› äº‘ç«¯ç½‘ç»œé™åˆ¶ï¼ŒCNN æš‚æ—¶æ— æ³•è¿æ¥ï¼Œå½“å‰æ˜¾ç¤ºåŸºäº RSI çš„æ¨¡æ‹Ÿæƒ…ç»ªå€¼ã€‚")

except Exception as e:
    st.error(f"æ ¸å¿ƒæ•°æ®åŠ è½½å¤±è´¥: {e}")

# --- 5. æ–°é—»æƒ…æŠ¥æµ ---
st.markdown("---")
st.subheader("3. å…¨çƒæƒ…æŠ¥æµ")

rss_feeds = {
    "Goldman Sachs": "https://news.google.com/rss/search?q=Goldman+Sachs+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Morgan Stanley": "https://news.google.com/rss/search?q=Morgan+Stanley+market+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Market Risk": "https://news.google.com/rss/search?q=stock+market+crash+warning+when:2d&hl=en-US&gl=US&ceid=US:en"
}

all_news = []
for src, url in rss_feeds.items():
    try:
        f = feedparser.parse(url)
        for e in f.entries:
            ts = 0
            time_str = ""
            if hasattr(e, 'published_parsed') and e.published_parsed:
                ts = time.mktime(e.published_parsed)
                time_str = datetime.datetime.fromtimestamp(ts).strftime('%m-%d %H:%M')
            all_news.append({"source": src, "title": e.title, "link": e.link, "time_str": time_str, "timestamp": ts})
    except: pass

all_news.sort(key=lambda x: x['timestamp'], reverse=True)

c_ai, c_list = st.columns([1, 1.5])

with c_ai:
    st.markdown("#### ğŸ§  DeepSeek ç ”æŠ¥")
    if st.button("âš¡ ç”Ÿæˆç®€æŠ¥", type="primary"):
        if not api_key: st.warning("è¯·å…ˆè®¾ç½® API Key")
        else:
            context = "\n".join([f"- [{n['source']}] {n['title']}" for n in all_news[:10]])
            try:
                client = OpenAI(api_key=api_key, base_url=BASE_URL)
                prompt = f"æ ¹æ®æœ€æ–°æ–°é—»åˆ†æç¾è‚¡é£é™©:\n{context}\nè¾“å‡ºä¸­æ–‡ç®€æŠ¥: 1.é£é™©è¯„åˆ† 2.å¤šç©ºè§‚ç‚¹ 3.æ“ä½œå»ºè®®"
                with st.spinner("åˆ†æä¸­..."):
                    resp = client.chat.completions.create(
                        model=MODEL_NAME, messages=[{"role":"user", "content":prompt}])
                    st.success("å®Œæˆ")
                    st.markdown(resp.choices[0].message.content)
            except Exception as e: st.error(str(e))

with c_list:
    st.markdown("#### ğŸ“° èµ„è®¯æµ")
    container = st.container(height=600)
    with container:
        for n in all_news[:25]:
            label, color, score = analyze_sentiment_tag(n['title'])
            st.markdown(f":{color}[**{label}**] {n['title']}")
            st.caption(f"ğŸ•’ {n['time_str']} | {n['source']} | [åŸæ–‡]({n['link']})")
            st.divider()

if refresh_rate: time.sleep(1)
