import streamlit as st
import yfinance as yf
import pandas as pd
import feedparser
from openai import OpenAI
from textblob import TextBlob
import plotly.graph_objects as go
import requests
import datetime
import time

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="DeepSeek æ™ºèƒ½é£æ§ä»ªè¡¨ç›˜", layout="wide", page_icon="ğŸ¦ˆ")

# --- 2. ä¾§è¾¹æ ï¼šæ§åˆ¶ä¸­å¿ƒ ---
st.sidebar.title("âš™ï¸ æ§åˆ¶ä¸­å¿ƒ")

# A. è‡ªåŠ¨è·å– Secrets ä¸­çš„ API Key
# ä¼˜å…ˆè¯»å–äº‘ç«¯åå°é…ç½®ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå†æ˜¾ç¤ºè¾“å…¥æ¡†
if "DEEPSEEK_API_KEY" in st.secrets:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
    st.sidebar.success("âœ… API Key å·²ä»äº‘ç«¯å®‰å…¨åŠ è½½")
else:
    api_key = st.sidebar.text_input("DeepSeek API Key", type="password", placeholder="sk-...")

MODEL_NAME = "deepseek-chat"
BASE_URL = "https://api.deepseek.com"

# B. åˆ·æ–°æ§åˆ¶
st.sidebar.subheader("â±ï¸ åˆ·æ–°è®¾ç½®")
if st.sidebar.button("ğŸ”„ ç«‹å³åˆ·æ–°æ•°æ®", type="primary"):
    st.rerun()

refresh_rate = st.sidebar.slider("è‡ªåŠ¨åˆ·æ–° (åˆ†é’Ÿ)", 5, 60, 30)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”— å¿«æ·å…¥å£")
st.sidebar.markdown("[ğŸ“… è´¢ç»æ—¥å†](https://cn.investing.com/economic-calendar/)")
st.sidebar.caption(f"æ›´æ–°æ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}")

# --- 3. åˆå§‹åŒ– AI è®°å¿† (Session State) ---
# è¿™æ˜¯é¡µé¢åˆ·æ–°ä¸ä¸¢å¤±å†…å®¹çš„å…³é”®
if 'ai_history' not in st.session_state:
    st.session_state['ai_history'] = [] # å­˜å‚¨å†å²æŠ¥å‘Šåˆ—è¡¨

# --- 4. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

@st.cache_data(ttl=3600) 
def get_cnn_fear_greed_index():
    try:
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://www.cnn.com/"
        }
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            data = r.json()
            return int(data['fear_and_greed_historical']['data'][-1]['y']), "CNN å®˜æ–¹æ•°æ®"
        return None, None
    except: return None, None

def plot_gauge(score, source):
    if score is None: return go.Figure()
    color = "#GRAY"
    if score > 75: color = "#FF4B4B"
    elif score > 55: color = "#FF8C00"
    elif score < 25: color = "#006400"
    elif score < 45: color = "#00CC96"
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number", value = score,
        title = {'text': f"å¸‚åœºæƒ…ç»ª ({source})", 'font': {'size': 18}},
        number = {'font': {'size': 40, 'color': color}},
        gauge = {'axis': {'range': [0, 100]}, 'bar': {'color': color},
                 'steps': [{'range': [0, 25], 'color': 'rgba(0,255,0,0.2)'}, {'range': [75, 100], 'color': 'rgba(255,0,0,0.2)'}]}
    ))
    fig.update_layout(height=250, margin=dict(l=10, r=10, t=40, b=10))
    return fig

def analyze_sentiment_tag(text):
    s = TextBlob(text).sentiment.polarity
    if s > 0.3: return "ğŸŸ¢ æåº¦ä¹è§‚", "green"
    elif 0.1 < s <= 0.3: return "ğŸ¥¬ åå¤š", "green"
    elif -0.1 <= s <= 0.1: return "âšª ä¸­æ€§", "gray"
    elif -0.3 <= s < -0.1: return "ğŸŸ  åç©º", "orange"
    else: return "ğŸ”´ æåº¦æ‚²è§‚", "red"

@st.cache_data(ttl=300)
def get_market_data():
    return yf.Tickers("SPY QQQ IEF").history(period="3mo")

# --- 5. ä¸»ç•Œé¢ ---
st.title("ğŸ¦ˆ åå°”è¡—é£å‘æ ‡ (AI Memory Ver.)")
st.caption(f"å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

try:
    # æ•°æ®ä¸å›¾è¡¨
    market_data = get_market_data()
    spy = market_data['Close']['SPY'].dropna()
    qqq = market_data['Close']['QQQ'].dropna()
    ief = market_data['Close']['IEF'].dropna()
    
    cnn_score, cnn_src = get_cnn_fear_greed_index()
    if cnn_score is None:
        # RSI Backup
        delta = spy.diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss
        cnn_score = 100 - (100 / (1 + rs)).iloc[-1]
        cnn_src = "RSI æ¨¡æ‹Ÿå€¼"

    c1, c2 = st.columns([2, 1])
    with c1:
        st.subheader("1. æ ¸å¿ƒèµ„äº§")
        m1, m2, m3 = st.columns(3)
        m1.metric("æ ‡æ™®500", f"${spy.iloc[-1]:.1f}", f"{spy.iloc[-1]-spy.iloc[-2]:.2f}")
        m2.metric("çº³æŒ‡QQQ", f"${qqq.iloc[-1]:.1f}", f"{qqq.iloc[-1]-qqq.iloc[-2]:.2f}")
        m3.metric("å›½å€ºIEF", f"${ief.iloc[-1]:.1f}", f"{ief.iloc[-1]-ief.iloc[-2]:.2f}")
        st.line_chart(pd.DataFrame({'SPY': spy, 'QQQ': qqq}), height=200)
    
    with c2:
        st.subheader("æƒ…ç»ªè¡¨")
        st.plotly_chart(plot_gauge(cnn_score, cnn_src), use_container_width=True)

except Exception as e: st.error(f"æ•°æ®é”™è¯¯: {e}")

# --- 6. AI æ™ºèƒ½æƒ…æŠ¥å° (å«è®°å¿†åŠŸèƒ½) ---
st.markdown("---")
st.subheader("3. DeepSeek æ™ºèƒ½ç ”æŠ¥ (å¸¦å†å²è®°å¿†)")

rss_feeds = {
    "Goldman": "https://news.google.com/rss/search?q=Goldman+Sachs+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Morgan": "https://news.google.com/rss/search?q=Morgan+Stanley+market+outlook+when:7d&hl=en-US&gl=US&ceid=US:en",
    "Risk": "https://news.google.com/rss/search?q=stock+market+crash+warning+when:2d&hl=en-US&gl=US&ceid=US:en"
}

# æŠ“å–æ–°é—»
all_news = []
for src, url in rss_feeds.items():
    try:
        f = feedparser.parse(url)
        for e in f.entries:
            ts = time.mktime(e.published_parsed) if hasattr(e, 'published_parsed') else 0
            all_news.append({"s": src, "t": e.title, "l": e.link, "ts": ts})
    except: pass
all_news.sort(key=lambda x: x['ts'], reverse=True)

# å¸ƒå±€
col_ai, col_news = st.columns([1, 1.5])

with col_ai:
    # æ˜¾ç¤ºå†å²åˆ†æè®°å½•
    if len(st.session_state['ai_history']) > 0:
        with st.expander("ğŸ“œ æŸ¥çœ‹ä¹‹å‰çš„åˆ†æè®°å½•", expanded=False):
            for i, report in enumerate(reversed(st.session_state['ai_history'])):
                st.caption(f"åˆ†ææ—¶é—´: {report['time']}")
                st.markdown(report['content'])
                st.divider()

    # ç”Ÿæˆæ–°åˆ†ææŒ‰é’®
    if st.button("âš¡ ç”Ÿæˆä»Šæ—¥æœ€æ–°ç ”æŠ¥ (å¯¹æ¯”æ—§è§‚ç‚¹)", type="primary"):
        if not api_key: st.warning("è¯·é…ç½® API Key")
        else:
            # 1. å‡†å¤‡ä¸Šä¸‹æ–‡
            latest_news = "\n".join([f"- [{n['s']}] {n['t']}" for n in all_news[:10]])
            
            # 2. è·å–ä¸Šä¸€æ¡å†å²è®°å½•ï¼ˆå¦‚æœæœ‰ï¼‰
            previous_context = ""
            if len(st.session_state['ai_history']) > 0:
                last_report = st.session_state['ai_history'][-1]['content']
                previous_context = f"\n\nã€ä½ ä¸Šä¸€æ¬¡çš„åˆ†æç»“è®ºæ˜¯ã€‘ï¼š\n{last_report}\n\nè¯·å°†ä¸Šé¢çš„æ—§è§‚ç‚¹ä¸ä¸‹é¢çš„æ–°æ–°é—»è¿›è¡Œæ¯”å¯¹ï¼š"
            else:
                previous_context = "\nè¿™æ˜¯ç¬¬ä¸€æ¬¡åˆ†æï¼Œè¯·å»ºç«‹åŸºå‡†è§‚ç‚¹ã€‚"

            # 3. æ„å»ºè¶…çº§ Prompt
            prompt = f"""
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åå°”è¡—é£æ§å®˜ã€‚
            {previous_context}

            ã€ä»Šæ—¥æœ€æ–°æ–°é—»æµã€‘ï¼š
            {latest_news}

            è¯·è¾“å‡ºä¸­æ–‡ç®€æŠ¥ï¼ˆMarkdownæ ¼å¼ï¼‰ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
            1. **ğŸ”„ è§‚ç‚¹å˜åŒ–**ï¼š(å¯¹æ¯”ä½ ä¸Šæ¬¡çš„åˆ†æï¼Œå¸‚åœºæƒ…ç»ªæ˜¯å˜å¥½äº†è¿˜æ˜¯å˜åäº†ï¼Ÿ)
            2. **ğŸš¨ æ ¸å¿ƒé£é™©æ›´æ–°**ï¼š(å½“å‰æœ€å¤§çš„é›·æ˜¯ä»€ä¹ˆï¼Ÿ)
            3. **ğŸ’¡ æœ€æ–°æ“ä½œå»ºè®®**ï¼š(é’ˆå¯¹SPY/QQQçš„å»ºè®®)
            """

            try:
                with st.spinner("æ­£åœ¨å¯¹æ¯”å†å²è§‚ç‚¹å¹¶åˆ†ææ–°æ•°æ®..."):
                    client = OpenAI(api_key=api_key, base_url=BASE_URL)
                    resp = client.chat.completions.create(
                        model=MODEL_NAME, messages=[{"role":"user", "content":prompt}])
                    
                    new_content = resp.choices[0].message.content
                    
                    # 4. å­˜å…¥è®°å¿†
                    st.session_state['ai_history'].append({
                        'time': datetime.datetime.now().strftime('%H:%M'),
                        'content': new_content
                    })
                    st.rerun() # é‡æ–°è¿è¡Œä»¥æ˜¾ç¤ºæœ€æ–°ç»“æœ
            except Exception as e: st.error(str(e))

    # å§‹ç»ˆæ˜¾ç¤ºæœ€æ–°çš„ä¸€æ¡åˆ†æ
    if len(st.session_state['ai_history']) > 0:
        latest = st.session_state['ai_history'][-1]
        st.success(f"ğŸ“Š æœ€æ–°åˆ†æ ({latest['time']})")
        st.markdown(latest['content'])
    else:
        st.info("ğŸ‘ˆ ç‚¹å‡»æŒ‰é’®ç”Ÿæˆä»Šæ—¥ç¬¬ä¸€ä»½ç ”æŠ¥")

with col_news:
    st.markdown("#### ğŸ“° å®æ—¶èµ„è®¯")
    with st.container(height=600):
        for n in all_news[:20]:
            label, color = analyze_sentiment_tag(n['t'])
            st.markdown(f":{color}[**{label}**] {n['t']}")
            st.caption(f"{n['s']} | [åŸæ–‡]({n['l']})")
            st.divider()

if refresh_rate: time.sleep(1)
